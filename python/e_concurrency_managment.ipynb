{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e29073",
   "metadata": {},
   "source": [
    "# Concurrency Management in Python\n",
    "\n",
    "Welcome to the comprehensive guide on concurrency in Python! This notebook will teach you how to make your programs run multiple tasks simultaneously, making them faster and more efficient.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to run multiple tasks at the same time (concurrency)\n",
    "- Three different approaches: Threading, Multiprocessing, and AsyncIO\n",
    "- When to use each approach with real-world examples\n",
    "- Best practices to write safe and efficient concurrent code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809539e5",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction to Concurrency](#1-introduction-to-concurrency)\n",
    "2. [Threading - Running Tasks Simultaneously](#2-threading)\n",
    "   - [Basic Threading](#basic-threading)\n",
    "   - [ThreadPoolExecutor (Recommended)](#21-threadpoolexecutor-with-concurrentfutures)\n",
    "3. [Multiprocessing - True Parallel Processing](#3-multiprocessing)\n",
    "   - [Basic Multiprocessing](#basic-multiprocessing)\n",
    "   - [ProcessPoolExecutor (Recommended)](#22-processpoolexecutor-with-concurrentfutures)\n",
    "4. [AsyncIO - Asynchronous Programming](#4-asyncio-asynchronous-programming)\n",
    "5. [When to Use Each Approach](#5-when-to-use-each-approach)\n",
    "6. [Best Practices and Common Pitfalls](#6-best-practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b22a15",
   "metadata": {},
   "source": [
    "## 1. Introduction to Concurrency\n",
    "\n",
    "**What is Concurrency?**\n",
    "Imagine you're cooking dinner. Instead of:\n",
    "1. Boiling water for pasta (wait 10 minutes)\n",
    "2. Then chopping vegetables (5 minutes)\n",
    "3. Then cooking sauce (8 minutes)\n",
    "\n",
    "You could do all three tasks \"concurrently\" - start the water boiling, chop vegetables while it heats, then start the sauce. This saves time!\n",
    "\n",
    "**In Programming:**\n",
    "Concurrency allows your program to handle multiple tasks at the same time, making it faster and more responsive.\n",
    "\n",
    "**Python's Three Main Approaches:**\n",
    "\n",
    "| Approach | Real-World Analogy | Best For | Example Use Case |\n",
    "|----------|-------------------|----------|------------------|\n",
    "| **Threading** | One chef switching between tasks | I/O operations (waiting for files, network) | Downloading multiple files |\n",
    "| **Multiprocessing** | Multiple chefs working independently | CPU-intensive tasks | Mathematical calculations |\n",
    "| **AsyncIO** | One very efficient chef with a task scheduler | Many I/O operations efficiently | Web server handling many requests |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065b47d",
   "metadata": {},
   "source": [
    "## 2. Threading - Running Tasks Simultaneously\n",
    "\n",
    "**What is Threading?**\n",
    "Think of threading like a single person (your program) who can switch quickly between multiple tasks. The person shares the same workspace (memory) but can work on different things.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Thread**: A separate flow of execution within your program\n",
    "- **Shared Memory**: All threads can access the same variables\n",
    "- **Good for I/O-bound tasks**: When your program waits for files, network, or user input\n",
    "\n",
    "**Real-world example**: While downloading a file (waiting), your program can update the UI or process other requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce0f400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting both tasks...\n",
      "Number: 0\n",
      "Letter: a\n",
      "Number: 1\n",
      "Letter: b\n",
      "Number: 1\n",
      "Letter: b\n",
      "Number: 2\n",
      "Letter: c\n",
      "Number: 2\n",
      "Letter: c\n",
      "Number: 3\n",
      "Letter: d\n",
      "Number: 3\n",
      "Letter: d\n",
      "Number: 4\n",
      "Letter: e\n",
      "Number: 4\n",
      "Letter: e\n",
      "Both tasks completed!\n",
      "Both tasks completed!\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def print_numbers():\n",
    "    \"\"\"This function prints numbers 0-4, with a 0.5 second pause between each\"\"\"\n",
    "    for i in range(5):\n",
    "        print(f\"Number: {i}\")\n",
    "        time.sleep(0.5)  # Simulate some work/waiting\n",
    "\n",
    "def print_letters():\n",
    "    \"\"\"This function prints letters a-e, with a 0.5 second pause between each\"\"\"\n",
    "    for letter in \"abcde\":\n",
    "        print(f\"Letter: {letter}\")\n",
    "        time.sleep(0.5)  # Simulate some work/waiting\n",
    "\n",
    "# Step 1: Create threads (like hiring two workers for different tasks)\n",
    "thread1 = threading.Thread(target=print_numbers)\n",
    "thread2 = threading.Thread(target=print_letters)\n",
    "\n",
    "# Step 2: Start both threads (both workers start working simultaneously)\n",
    "print(\"Starting both tasks...\")\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Step 3: Wait for both threads to finish (wait for both workers to complete)\n",
    "thread1.join()  # Wait for numbers to finish\n",
    "thread2.join()  # Wait for letters to finish\n",
    "\n",
    "print(\"Both tasks completed!\")\n",
    "\n",
    "# Without threading, this would take 5 seconds (2.5 + 2.5)\n",
    "# With threading, it takes about 2.5 seconds (both run simultaneously)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115bd05",
   "metadata": {},
   "source": [
    "## 3. Multiprocessing - True Parallel Processing\n",
    "\n",
    "**What is Multiprocessing?**\n",
    "Think of multiprocessing like hiring multiple chefs to work in separate kitchens. Each chef (process) has their own complete kitchen (memory space) and can work independently without interfering with others.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Process**: A completely separate program instance with its own memory\n",
    "- **True Parallelism**: Multiple processes can run simultaneously on different CPU cores\n",
    "- **Good for CPU-bound tasks**: Mathematical calculations, data processing, image manipulation\n",
    "\n",
    "**Real-world example**: Processing thousands of images - each process handles different images independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f1146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting multiprocessing calculation...\n",
      "\n",
      "🔢 Worker-1 calculating factorial of 5\n",
      "🔢 Worker-1 calculating factorial of 5\n",
      "🔢 Worker-2 calculating factorial of 6\n",
      "🔢 Worker-3 calculating factorial of 4\n",
      "🔢 Worker-2 calculating factorial of 6\n",
      "🔢 Worker-3 calculating factorial of 4\n",
      "✅ Worker-1 completed: 5! = 120\n",
      "✅ Worker-3 completed: 4! = 24\n",
      "✅ Worker-1 completed: 5! = 120\n",
      "✅ Worker-3 completed: 4! = 24\n",
      "✅ Worker-2 completed: 6! = 720\n",
      "\n",
      "🎉 All calculations completed!\n",
      "✅ Worker-2 completed: 6! = 720\n",
      "\n",
      "🎉 All calculations completed!\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, current_process\n",
    "\n",
    "def calculate_factorial(n):\n",
    "    \"\"\"Calculate factorial and demonstrate CPU-intensive work\"\"\"\n",
    "    print(f\"🔢 {current_process().name} calculating factorial of {n}\")\n",
    "    \n",
    "    # Simulate CPU-intensive work\n",
    "    result = 1\n",
    "    for i in range(1, n + 1):\n",
    "        result *= i\n",
    "        time.sleep(0.01)  # Small delay to simulate work\n",
    "    \n",
    "    print(f\"✅ {current_process().name} completed: {n}! = {result}\")\n",
    "    return result\n",
    "\n",
    "print(\"🚀 Starting multiprocessing calculation...\\n\")\n",
    "\n",
    "# Create processes for different calculations\n",
    "process1 = Process(target=calculate_factorial, args=(5,), name=\"Worker-1\")\n",
    "process2 = Process(target=calculate_factorial, args=(6,), name=\"Worker-2\")\n",
    "process3 = Process(target=calculate_factorial, args=(4,), name=\"Worker-3\")\n",
    "\n",
    "# Start all processes\n",
    "process1.start()\n",
    "process2.start()\n",
    "process3.start()\n",
    "\n",
    "# Wait for all to complete\n",
    "process1.join()\n",
    "process2.join()\n",
    "process3.join()\n",
    "\n",
    "print(\"\\n🎉 All calculations completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a20f5",
   "metadata": {},
   "source": [
    "## 4. AsyncIO - Asynchronous Programming\n",
    "\n",
    "**What is AsyncIO?**\n",
    "Think of AsyncIO like a very efficient waiter at a restaurant. Instead of waiting for one customer's order to be prepared before taking another order, the waiter takes multiple orders and checks back when each is ready.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Asynchronous**: Tasks can pause and resume without blocking other tasks\n",
    "- **Single-threaded**: Everything runs in one thread, but efficiently\n",
    "- **Good for I/O-bound tasks**: Network requests, file operations, database queries\n",
    "\n",
    "**Real-world example**: A web server handling hundreds of simultaneous user requests efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e7aefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting concurrent API calls...\n",
      "\n",
      "🌐 Starting API call to Weather API\n",
      "🌐 Starting API call to News API\n",
      "🌐 Starting API call to Stock API\n",
      "✅ Received data from Weather API (took 1s)\n",
      "✅ Received data from Weather API (took 1s)\n",
      "✅ Received data from Stock API (took 1.5s)\n",
      "✅ Received data from Stock API (took 1.5s)\n",
      "✅ Received data from News API (took 2s)\n",
      "\n",
      "📋 All API calls completed!\n",
      "   - Data from Weather API\n",
      "   - Data from News API\n",
      "   - Data from Stock API\n",
      "✅ Received data from News API (took 2s)\n",
      "\n",
      "📋 All API calls completed!\n",
      "   - Data from Weather API\n",
      "   - Data from News API\n",
      "   - Data from Stock API\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def fetch_data(api_name, delay):\n",
    "    \"\"\"Simulates fetching data from an API\"\"\"\n",
    "    print(f\"🌐 Starting API call to {api_name}\")\n",
    "    await asyncio.sleep(delay)  # Simulate network delay\n",
    "    print(f\"✅ Received data from {api_name} (took {delay}s)\")\n",
    "    return f\"Data from {api_name}\"\n",
    "\n",
    "async def main():\n",
    "    \"\"\"Main async function that coordinates all API calls\"\"\"\n",
    "    print(\"🚀 Starting concurrent API calls...\\n\")\n",
    "    \n",
    "    # Start all API calls concurrently\n",
    "    results = await asyncio.gather(\n",
    "        fetch_data(\"Weather API\", 1),\n",
    "        fetch_data(\"News API\", 2),\n",
    "        fetch_data(\"Stock API\", 1.5)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📋 All API calls completed!\")\n",
    "    for result in results:\n",
    "        print(f\"   - {result}\")\n",
    "\n",
    "# Run the async program\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c04d08",
   "metadata": {},
   "source": [
    "## 5. When to Use Each Approach - Decision Guide\n",
    "\n",
    "**Quick Decision Tree:**\n",
    "\n",
    "1. **Is your task waiting for something external (files, network, database)?**\n",
    "   - YES → Go to step 2\n",
    "   - NO → Use **Multiprocessing** (CPU-bound task)\n",
    "\n",
    "2. **Do you need to handle many (100+) simultaneous operations?**\n",
    "   - YES → Use **AsyncIO** (most efficient for many I/O operations)\n",
    "   - NO → Use **Threading** (simpler for few I/O operations)\n",
    "\n",
    "**Detailed Comparison:**\n",
    "\n",
    "| Scenario | Best Choice | Why? | Example |\n",
    "|----------|-------------|------|---------|\n",
    "| Downloading 10 files | **Threading** | Simple, good for moderate I/O | Web scraping |\n",
    "| Processing 1000 images | **Multiprocessing** | Uses all CPU cores | Image resizing |\n",
    "| Web server (1000+ users) | **AsyncIO** | Handles many connections efficiently | REST API |\n",
    "| Mathematical calculations | **Multiprocessing** | Bypasses Python's GIL limitation | Data analysis |\n",
    "| Reading multiple databases | **Threading** or **AsyncIO** | Depends on scale | Data collection |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12957db2",
   "metadata": {},
   "source": [
    "## 6. Best Practices and Common Pitfalls\n",
    "\n",
    "**✅ DO:**\n",
    "- **Start simple**: Use ThreadPoolExecutor or ProcessPoolExecutor instead of manual thread/process management\n",
    "- **Profile first**: Measure your code before optimizing - you might not need concurrency!\n",
    "- **Handle exceptions**: Always use try/except blocks in concurrent code\n",
    "- **Use context managers**: `with ThreadPoolExecutor() as executor:` automatically cleans up resources\n",
    "\n",
    "**❌ DON'T:**\n",
    "- **Share mutable state**: Avoid global variables in threading - use locks if necessary\n",
    "- **Mix approaches unnecessarily**: Pick one concurrency model per problem\n",
    "- **Assume faster**: More threads/processes ≠ faster performance (overhead exists!)\n",
    "- **Forget the GIL**: Python's Global Interpreter Lock limits threading for CPU tasks\n",
    "\n",
    "**🛠️ Common Debugging Tips:**\n",
    "- **Deadlocks**: When threads wait for each other forever - use timeouts\n",
    "- **Race conditions**: When threads compete for resources - use locks\n",
    "- **Resource exhaustion**: Don't create unlimited threads/processes - use pools\n",
    "\n",
    "**📝 Code Example - Error Handling:**\n",
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "\n",
    "def safe_download(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        return f\"✅ {url}: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ {url}: {str(e)}\"\n",
    "\n",
    "# Always handle errors in concurrent code!\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    urls = [\"http://example.com\", \"http://invalid-url\"]\n",
    "    results = list(executor.map(safe_download, urls))\n",
    "    for result in results:\n",
    "        print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710525b0",
   "metadata": {},
   "source": [
    "## 2.1 ThreadPoolExecutor - The Professional Way\n",
    "\n",
    "**Why use ThreadPoolExecutor?**\n",
    "While basic threading works, manually managing threads can be tricky and error-prone. `ThreadPoolExecutor` is like having a professional task manager that:\n",
    "- Creates and destroys threads for you\n",
    "- Manages the optimal number of threads\n",
    "- Handles errors gracefully\n",
    "- Makes your code cleaner and safer\n",
    "\n",
    "**When to use this:**\n",
    "- When you have many I/O-bound tasks (file reading, web requests, database queries)\n",
    "- When you want simple, clean code without manual thread management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb44a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting concurrent downloads...\n",
      "\n",
      "📥 Starting download: document.pdf (2MB)\n",
      "📥 Starting download: image.jpg (1MB)\n",
      "📥 Starting download: video.mp4 (4MB)\n",
      "✅ Completed download: image.jpg\n",
      "📥 Starting download: music.mp3 (3MB)\n",
      "📋 Result: image.jpg downloaded successfully\n",
      "✅ Completed download: image.jpg\n",
      "📥 Starting download: music.mp3 (3MB)\n",
      "📋 Result: image.jpg downloaded successfully\n",
      "✅ Completed download: document.pdf\n",
      "📋 Result: document.pdf downloaded successfully\n",
      "✅ Completed download: document.pdf\n",
      "📋 Result: document.pdf downloaded successfully\n",
      "✅ Completed download: video.mp4\n",
      "📋 Result: video.mp4 downloaded successfully\n",
      "✅ Completed download: music.mp3\n",
      "📋 Result: music.mp3 downloaded successfully\n",
      "\n",
      "🎉 All downloads completed!\n",
      "✅ Completed download: video.mp4\n",
      "📋 Result: video.mp4 downloaded successfully\n",
      "✅ Completed download: music.mp3\n",
      "📋 Result: music.mp3 downloaded successfully\n",
      "\n",
      "🎉 All downloads completed!\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def download_file(file_name, size_mb):\n",
    "    \"\"\"Simulates downloading a file\"\"\"\n",
    "    print(f\"📥 Starting download: {file_name} ({size_mb}MB)\")\n",
    "    time.sleep(size_mb * 0.5)  # Simulate download time (0.5 seconds per MB)\n",
    "    print(f\"✅ Completed download: {file_name}\")\n",
    "    return f\"{file_name} downloaded successfully\"\n",
    "\n",
    "# List of files to download\n",
    "files_to_download = [\n",
    "    (\"document.pdf\", 2),\n",
    "    (\"image.jpg\", 1),\n",
    "    (\"video.mp4\", 4),\n",
    "    (\"music.mp3\", 3)\n",
    "]\n",
    "\n",
    "print(\"🚀 Starting concurrent downloads...\\n\")\n",
    "\n",
    "# Using ThreadPoolExecutor (max 3 downloads at once)\n",
    "with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    # Submit all download tasks\n",
    "    futures = [executor.submit(download_file, name, size) for name, size in files_to_download]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        print(f\"📋 Result: {result}\")\n",
    "\n",
    "print(\"\\n🎉 All downloads completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f569db",
   "metadata": {},
   "source": [
    "**When to use ThreadPoolExecutor:**\n",
    "- When you want to run many I/O-bound tasks concurrently with a simple interface.\n",
    "- It manages thread creation, scheduling, and joining for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7007d",
   "metadata": {},
   "source": [
    "## 3.1 ProcessPoolExecutor - The Professional Way for CPU Tasks\n",
    "\n",
    "**Why use ProcessPoolExecutor?**\n",
    "While basic multiprocessing works, `ProcessPoolExecutor` is like having a professional project manager for CPU-intensive work:\n",
    "- Automatically manages multiple processes for you\n",
    "- Distributes work efficiently across CPU cores\n",
    "- Handles process creation, communication, and cleanup\n",
    "- Bypasses Python's GIL (Global Interpreter Lock) for true parallelism\n",
    "\n",
    "**When to use this:**\n",
    "- CPU-intensive tasks (math calculations, data processing, image manipulation)\n",
    "- When you want to utilize all CPU cores efficiently\n",
    "- When you need simple, clean code for parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba55d380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Processing 20 items using 4 workers...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Worker 1 processing 5 items...🔄 Worker 2 processing 5 items...🔄 Worker 3 processing 5 items...🔄 Worker 4 processing 5 items...\n",
      "\n",
      "\n",
      "\n",
      "🔄 Worker 2 processing 5 items...🔄 Worker 3 processing 5 items...🔄 Worker 4 processing 5 items...\n",
      "\n",
      "\n",
      "\n",
      "✅ Worker 2 completed processing✅ Worker 1 completed processing✅ Worker 3 completed processing✅ Worker 4 completed processing\n",
      "\n",
      "\n",
      "\n",
      "✅ Worker 2 completed processing✅ Worker 1 completed processing✅ Worker 3 completed processing✅ Worker 4 completed processing\n",
      "\n",
      "\n",
      "\n",
      "📊 Chunk 2: 5 items → 330\n",
      "📊 Chunk 3: 5 items → 855\n",
      "📊 Chunk 1: 5 items → 55\n",
      "📊 Chunk 4: 5 items → 1630\n",
      "\n",
      "🎯 Final result: 2870\n",
      "🎉 All data processing completed!\n",
      "📊 Chunk 2: 5 items → 330\n",
      "📊 Chunk 3: 5 items → 855\n",
      "📊 Chunk 1: 5 items → 55\n",
      "📊 Chunk 4: 5 items → 1630\n",
      "\n",
      "🎯 Final result: 2870\n",
      "🎉 All data processing completed!\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "def process_data(data_chunk, chunk_id):\n",
    "    \"\"\"Simulates CPU-intensive data processing\"\"\"\n",
    "    print(f\"🔄 Worker {chunk_id} processing {len(data_chunk)} items...\")\n",
    "    \n",
    "    # Simulate CPU-intensive work (mathematical calculations)\n",
    "    result = sum(x ** 2 for x in data_chunk)\n",
    "    time.sleep(1)  # Simulate processing time\n",
    "    \n",
    "    print(f\"✅ Worker {chunk_id} completed processing\")\n",
    "    return {\"chunk_id\": chunk_id, \"result\": result, \"items_processed\": len(data_chunk)}\n",
    "\n",
    "# Large dataset to process\n",
    "large_dataset = list(range(1, 21))  # Numbers 1-20\n",
    "chunk_size = 5\n",
    "\n",
    "# Split data into chunks for parallel processing\n",
    "data_chunks = [\n",
    "    large_dataset[i:i + chunk_size] \n",
    "    for i in range(0, len(large_dataset), chunk_size)\n",
    "]\n",
    "\n",
    "print(f\"🚀 Processing {len(large_dataset)} items using {len(data_chunks)} workers...\\n\")\n",
    "\n",
    "# Using ProcessPoolExecutor (uses all CPU cores)\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    # Submit all processing tasks\n",
    "    futures = [\n",
    "        executor.submit(process_data, chunk, i+1) \n",
    "        for i, chunk in enumerate(data_chunks)\n",
    "    ]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    total_result = 0\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        total_result += result[\"result\"]\n",
    "        print(f\"📊 Chunk {result['chunk_id']}: {result['items_processed']} items → {result['result']}\")\n",
    "\n",
    "print(f\"\\n🎯 Final result: {total_result}\")\n",
    "print(\"🎉 All data processing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010b2a4",
   "metadata": {},
   "source": [
    "**When to use ProcessPoolExecutor:**\n",
    "- For CPU-bound tasks that benefit from true parallelism.\n",
    "- When you want a simple interface for running functions in separate processes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
